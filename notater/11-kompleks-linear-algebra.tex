\input{kapittel}

\kapittel{11}{Kompleks lineær algebra}
\label{ch:kompleks-linear-algebra}

I dette kapitlet er det fire sentrale poenger som skal drives gjennom:

\begin{itemize}
\item Skalarene i definisjonen av vektorrom kan være andre tall enn de reelle.

\item Lineæralgebra over $\mathbb C$ er stort sett helt likt som over $\R$.

\item Alle matriser har $n$ komplekse egenverdier om du teller med multiplisiteten deres.
 
\item Egenrommet har dimensjon mindre enn eller lik multiplisiteten til den tilhørende egenverdien.
\end{itemize}

\section*{Definisjonen av vektorrom II}

De rasjonale tallene $\Q$, de reelle tallene $\R$, 
og de komplekse tallene $\C$ er alle eksempler på et konsept kalt kropp. 
En kropp er et tallsystem med to regneoperasjoner $+$ og $\cdot$, 
som tilfredsstiller ti-tolv aksiomer, 
hvorav noen ligner ganske bra på vektorromsaksiomene. 
Vi skal ikke gå gjennom disse aksiomene, 
men sentralt for en kropp er at alle elementer i kroppen har multiplikativ invers.

Vektorromsaksiomene opererer med to 'ting' som kombineres, nemlig tall og vektorer. 
Tidligere har vi bare sagt at vektorer kan ganges med tall, 
men ikke åpnet for at disse tallene kan være noe annet enn reelle tall. 
Det skal vi gjøre noe med nå. 
Vi skal ikke endre på aksiomene for vektorrom, 
men vi skal begynne å spesifisere hva slags tall som kan ganges med vektorer. 

\begin{defn}
La $V$ være en mengde, og $K$ en kropp. Anta at vi har definert to operasjoner:
\begin{align*}
\text{addisjon av vektorer: } & \V{u} + \V{v} \\
\text{skalarmultiplikasjon: } & c \cdot \V{u}
\end{align*}
Addisjonen skal være definert for alle elementer $\V{u}$ og~$\V{v}$
i~$V$, og skalarmultiplikasjonen for alle skalarer~$c$ i $K$ og alle $\V{u}$
i~$V$.  Resultatet av operasjonene skal alltid være et element i~$V$.

Dersom mengden~$V$ og de to operasjonene oppfyller vektorromsaksiomene, 
så sier vi at $V$ er et \defterm{vektorrom} over $K$.
\end{defn}

\begin{ex}
$\R^n$ et vektorrom over $\R$.
\end{ex}

\begin{ex}
Vi skriver $\C^n$ for vektorrommet der $K=\C$ og komponentene i vektorene er hentet fra $\C$.
\end{ex}

\begin{ex}
$\Q^n$ et vektorrom over $\Q$. Merk at selv om vi har sagt at vi har gjort lineær algebra på $\R^n$ til nå, har vi i praksis operert på $\Q^n$. Ikke et eneste matriseeksempel har involvert $\sqrt{2}$.
\end{ex}

\begin{ex}
$\P^n$ er et vektorrom over $\mathbb R$ slik vi har jobbet med det til nå. 
Men det er ingenting i veien for å behandle det som et vektorrom over $\C$.
\end{ex}


\begin{ex}
De hele tallene $\Z$ er ikke en kropp, så en del av teoremene vi har bevist, gjelder ikke for $\Z^n$. 
For eksempel har et $n\times n$-ligningssystem med komponenter i $\Z$ og lineært uavhengige kolonner,  
ikke nødvendigvis noen løsning i $\Z^n$. 
\end{ex}



\section*{Lineær algebra over $\C$}

Vi starter dette avsnittet med en morsomt teorem. Så tar vi noen eksempler på lineæralgebra over $\C$.

\begin{thm}
Alle teoremer vi har bevist til nå, gjelder også for $\mathbb C^n$. 
\end{thm}




\begin{ex}
Vi begynner med å løse ligningssystemet
\begin{align*}
(1-i) z + 3w   &= 2-3i \\
i z + (1+2i) w &= 1
\end{align*}
som har totalmatrise
\[
\begin{amatrix}{2}
1-i & 3 & 2-3i \\ i &1+2i & 1
\end{amatrix}.
\]
Vi ønsker å kvitte oss med $i$-en til venstre i den andre raden, så vi begynner med å gange den første raden med $\frac{i}{1-i}$, og får
\[
\begin{amatrix}{2}
i & \frac{3i}{1-i} & \frac{3+2i}{1-i} 
\end{amatrix}.
\]
Vi trekker dette fra den andre raden og erstatter den andre raden med resultatet
\[
\begin{amatrix}{2}
1-i & 3 & 2-3i \\ 0 &1+2i -\frac{3i}{1-i} & 1-\frac{3+2i}{1-i} 
\end{amatrix}.
\]
Jeg tror vi ganger den andre raden med $1-i$ for å rydde litt
\[
\begin{amatrix}{2}
1-i & 3 & 2-3i \\ 0 &3 -2i  & -2-3i.
\end{amatrix}.
\]
Vi er nå klare for å finne $w$
\[
w=\frac{-2-3i}{3-2i}=\frac{-2-3i}{3-2i}\cdot \frac{3+2i}{3+2i}=-i,
\]
og $z$
\[
z=\frac{2-3i-3(-i)}{1-i}=1+i.
\]
\end{ex}

\begin{ex}
Det kan verifiseres at inversen til 
\[
\begin{bmatrix}
1-i & 3  \\ i &1+2i 
\end{bmatrix}
\]
er
\[
\frac{1}{3-2i}
\begin{bmatrix}
1+2i & -3  \\ -i &1-i 
\end{bmatrix}
\]
ved å gange dem sammen
\[
\frac{1}{3-2i}
\begin{bmatrix}
1-i & 3  \\ i &1+2i 
\end{bmatrix}
\begin{bmatrix}
1+2i & -3  \\ -i &1-i 
\end{bmatrix}
=
\begin{bmatrix}
1 & 0  \\ 0 &1 
\end{bmatrix}.
\]


\end{ex}

\begin{ex}
Vi sjekker lineær uavhengighet akkurat som i det reelle tilfellet, altså ved gausseliminasjon. Determinanten forteller om $n$ vektorer i $\mathbb C^n$ er er lineært uavhengige.
\end{ex}

\begin{ex}
Standardbasisen for $\R^n$ er også en basis for $\C^n$. Det er lett å se at alle elementer i $\C$ kan skrives som en unik lineærkombinasjon av elementene i basisen.
\end{ex}



\section*{Komplekse polynomer}

Algebraens fundamentalteorem sier at likningen
\[
a_nz^n+a_{n-1}z^{n-1}+...+a_1z+a_0=0
\]
alltid har $n$ komplekse løsninger, i den forstand at vi alltid kan skrive
\[
a_nz^n+a_{n-1}z^{n-1}+...+a_1z+a_0=\prod_{n=1}^n (z-z_i),
\]
der $z_i$ er polynomets røtter. Noen av disse kan være repeterte $k$ ganger, og da sier vi at de har multiplisitet $k$. 

\begin{ex}
Polynomet 
\[
z^3-3z^2+3z-1=(z-1)^3
\]
har en rot ($z=1$) med multiplisitet 3.
\end{ex}

%\begin{ex}
%Polynomet 
%\[
%=(z-1)(z+i)^2
%\]
%har en rot med multiplisitet ($z=1$) med multiplisitet 3.
%\end{ex}

\section*{Komplekse egenverdier}

\begin{thm}
Det karakteristiske polynomet har alltid orden $n$. 
En matrise har alltid $n$ egenverdier dersom du 
teller med multiplisiteten til hver egenverdi. 
\end{thm}

\begin{ex}
Matrisen
\[
\begin{pmatrix}
0 & -1 \\ 1 &0
\end{pmatrix}
\]
har visst egenvektorer allikevel. Den karakteristiske ligningen er 
\[
\lambda^2+1=0,
\]
så egenverdiene er $\pm i$. 
\end{ex}

\begin{ex}
Matrisen
\[
\begin{pmatrix}
1 & -1 & 0\\ 1 &1 &0 \\ 0 & 0 & 3
\end{pmatrix}
\]
har karakteristisk ligning
\[
((1-\lambda)^2+1)(3-\lambda)=(2-2\lambda+\lambda^2)(3-\lambda),
\]
så egenverdiene er $\lambda=3$ og
\[
\lambda=\frac{2\pm\sqrt{4-8}}{2}=1\pm i.
\] 
\end{ex}

\begin{thm}
Egenverdiene til en reell matrise kommer i komplekskonjugerte par.
\end{thm}


\begin{ex}
Matrisen
\[
\begin{pmatrix}
1 & 1 & 0\\  0 &1 & 0 \\ 0 & 0 & 2
\end{pmatrix}
\]
har karakteristisk ligning
\[
(2-\lambda)(1-\lambda)^2=0,
\]
med en enkel egenverdi $\lambda=2$, og en dobbel egenverdi $\lambda=1$. 
\end{ex}


\section*{Mer om egenrommet}
Egenrommet til egenverdien $\lambda$ er nullrommet til matrisen $A-\lambda I$.
En matrise har alltid $n$ egenverdier, 
men ikke nødvendigvis $n$ lineært uavhengige egenvektorer.

\begin{ex}
Matrisen
\[
\begin{pmatrix}
0 & -1 \\ 1 &0
\end{pmatrix}
\]
egenverdier
\[
\lambda=\pm i.
\] 
Egenvektorer for egenverdiene er 
\[
\begin{pmatrix}
1  \\ i
\end{pmatrix}
\quad \text{og }\quad
\begin{pmatrix}
i  \\ 1
\end{pmatrix}.
\]
\end{ex}

\begin{ex}
Matrisen
\[
\begin{pmatrix}
1 & 1 & 0\\  0 &1 & 0 \\ 0 & 0 & 2
\end{pmatrix}
\]
har dobbel egenverdi $\lambda=1$. Egenrommet er nullrommet til 
\[
\begin{pmatrix}
0 & 1 & 0\\  0 &0 & 0 \\ 0 & 0 & 1
\end{pmatrix}
\]
altså ikketrivielle løsninger av 

\[
\begin{pmatrix}
0 & 1 & 0\\  0 &0 & 0 \\ 0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
x_1  \\ x_2 \\ x_3
\end{pmatrix}
=
\begin{pmatrix}
0  \\ 0 \\0
\end{pmatrix}
\]
Dette systemet sier at
$
x_2=x_3=0,
$
og ingenting mer, så egenrommet til $\lambda=1$ er
\[
\Sp \left\{ \vvv{1}{0}{0} \right\}.
\]
\end{ex}


\begin{thm}
Egenrommet har dimensjon mindre enn eller lik multiplisiteten til egenverdien. 
\end{thm}

Dersom et egenrom har lavere dimensjon enn multiplisiteten til egenverdien, sier vi at egenverdien er \defterm{defekt}. 
Dersom en $n\times n$-matrise har $n$ lineært uavhengige egenvektorer, sier vi at den er \defterm{diagonaliserbar}.
Grunnen til dette navnet skal vi komme tilbake til.





\kapittelslutt
